# **Data Engineering Project with E-Commerce Olist Dataset using PySpark**

---

## **Aim & Description**
This project demonstrates the flow of data engineering project using **PySpark** to process real e-commerce datasets.  
The goal is to extract meaningful data by cleaning, transforming, joining, and analyzing ecommerce olist dataset on a **distributed environment using Google Cloud Platform (GCP)**.

---

## **Source of Data**
The dataset was originally from Kaggle: https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce

---

## **Tools**
- **PySpark**  
- **Google Cloud Storage (GCS)**
- **HDFS**  
- **Google Cloud Dataproc**
- **JupyterLab** (via Dataproc Notebooks)
- **BigQuery**
- **Looker Studio**

---

## **Flow Overview**
1. Data Ingestion & Exploration
2. Data Cleaning & Transformation
3. Data Integration & Aggregation
4. Property Optimization
5. Data Serving

---

> 📝 **Note**:  
> The entire project was developed using **PySpark in JupyterLab**, running on a **Google Cloud Dataproc cluster (non-autoscaling mode)**.  
> The project was implemented using the **free tier credits provided by Google Cloud Platform (GCP)**.  
> Cluster setup details can be found in the screenshot folder (**Config Cluster**).
